{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Final] v8 torch transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMvpdjHb4qWSoKhMI1BoYG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentZuo/fin-models/blob/main/%5BFinal%5D_v8_torch_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up and read data"
      ],
      "metadata": {
        "id": "itscQHfmMd3f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C5yRVW5XXkN",
        "outputId": "349a0d9d-cc44-4b61-c0e9-f1688aa2759e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.17.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (4.11.4)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (4.64.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 76.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.17.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.17.0) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=5cf46e045bcd52bcc5547bb1afbb0e2a3cb11d61404fa31857db429bdd34cccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.17.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 354 kB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.53)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=fb5e6504bf153175db18b7e2cbef584b59fc0899cf5ff6ffa4287b0986383ab7\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.0 sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.17.0\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "5MNCXjzfakUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "print(transformers.__version__)\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5WcNsUGLfP-",
        "outputId": "8b4c0c03-8740-4364-9b96-db2da391e437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.17.0\n",
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "X5rn8XsULlNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CnWaRtaLusP",
        "outputId": "f85610e5-01fe-4031-d745-f380ea4132fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_df = pd.read_pickle(\"/content/gdrive/MyDrive/224U_2022/final_project_data.pkl\")"
      ],
      "metadata": {
        "id": "Fc2Xi8lFLF2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g67xi32MLqwX",
        "outputId": "b31fc823-36d6-4a8c-81d5-b07dbb153a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           title  \\\n",
              "0                               Joseph Greenberg   \n",
              "1                                Pauline Donalda   \n",
              "2  List of German football transfers summer 2017   \n",
              "3                                  Lester Hudson   \n",
              "4                              Monique Ganderton   \n",
              "\n",
              "                                               label       range  \\\n",
              "0  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...    (0, 106)   \n",
              "1  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  (106, 127)   \n",
              "2                                    [0, 0, 1, 0, 0]  (127, 132)   \n",
              "3  [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, ...  (132, 176)   \n",
              "4                              [1, 0, 0, 0, 0, 1, 0]  (176, 183)   \n",
              "\n",
              "                                                 emb  \n",
              "0  [[-0.07557425, -0.011484241, -0.07807306, 0.00...  \n",
              "1  [[-0.057122264, 0.005889078, -0.030671664, -0....  \n",
              "2  [[-0.0032938644, -0.02310217, -0.05397396, -0....  \n",
              "3  [[-0.0091192825, 0.090078354, -0.029187214, -0...  \n",
              "4  [[-0.090651, -0.09176681, -0.029592248, -0.062...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28fc21ba-56cf-4a1d-b3d4-024b853c2208\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "      <th>range</th>\n",
              "      <th>emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joseph Greenberg</td>\n",
              "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
              "      <td>(0, 106)</td>\n",
              "      <td>[[-0.07557425, -0.011484241, -0.07807306, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pauline Donalda</td>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
              "      <td>(106, 127)</td>\n",
              "      <td>[[-0.057122264, 0.005889078, -0.030671664, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>List of German football transfers summer 2017</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>(127, 132)</td>\n",
              "      <td>[[-0.0032938644, -0.02310217, -0.05397396, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lester Hudson</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, ...</td>\n",
              "      <td>(132, 176)</td>\n",
              "      <td>[[-0.0091192825, 0.090078354, -0.029187214, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Monique Ganderton</td>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>(176, 183)</td>\n",
              "      <td>[[-0.090651, -0.09176681, -0.029592248, -0.062...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28fc21ba-56cf-4a1d-b3d4-024b853c2208')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28fc21ba-56cf-4a1d-b3d4-024b853c2208 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28fc21ba-56cf-4a1d-b3d4-024b853c2208');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_df = read_df.sample(frac=1)\n",
        "read_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9vppdy_09HWq",
        "outputId": "984c88b2-3418-4f6c-bc20-9267c936482d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          title  \\\n",
              "793           Henry Charbonneau   \n",
              "504              Wild West City   \n",
              "1007             Mikkel Aagaard   \n",
              "1820  Frederik Hendrikplantsoen   \n",
              "500             Jane Somerville   \n",
              "\n",
              "                                                  label           range  \\\n",
              "793             [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]  (16145, 16158)   \n",
              "504                                              [1, 0]  (10505, 10507)   \n",
              "1007                        [1, 1, 0, 0, 1, 0, 0, 1, 0]  (20758, 20767)   \n",
              "1820                                             [0, 0]  (38642, 38644)   \n",
              "500   [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, ...    (9566, 9631)   \n",
              "\n",
              "                                                    emb  \n",
              "793   [[0.05722959, -0.008566863, -0.094458535, 0.00...  \n",
              "504   [[0.10378061, 0.071708806, -0.028881393, 0.004...  \n",
              "1007  [[-0.090821765, 0.018140187, 0.030428424, -0.0...  \n",
              "1820  [[0.13479649, 0.087804824, -0.01524276, -0.064...  \n",
              "500   [[-0.02891623, -0.043679826, 0.0065269014, -0....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28e2df36-fa0b-4325-83b9-de11ddacff12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>label</th>\n",
              "      <th>range</th>\n",
              "      <th>emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>Henry Charbonneau</td>\n",
              "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>(16145, 16158)</td>\n",
              "      <td>[[0.05722959, -0.008566863, -0.094458535, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>Wild West City</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>(10505, 10507)</td>\n",
              "      <td>[[0.10378061, 0.071708806, -0.028881393, 0.004...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>Mikkel Aagaard</td>\n",
              "      <td>[1, 1, 0, 0, 1, 0, 0, 1, 0]</td>\n",
              "      <td>(20758, 20767)</td>\n",
              "      <td>[[-0.090821765, 0.018140187, 0.030428424, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>Frederik Hendrikplantsoen</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>(38642, 38644)</td>\n",
              "      <td>[[0.13479649, 0.087804824, -0.01524276, -0.064...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>Jane Somerville</td>\n",
              "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
              "      <td>(9566, 9631)</td>\n",
              "      <td>[[-0.02891623, -0.043679826, 0.0065269014, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28e2df36-fa0b-4325-83b9-de11ddacff12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28e2df36-fa0b-4325-83b9-de11ddacff12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28e2df36-fa0b-4325-83b9-de11ddacff12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LENGTH = 128"
      ],
      "metadata": {
        "id": "1hU8JD3IFBTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "#Define the model\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "gVB6cBvYM2KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empty_sentence = sentence_model.encode([''])\n",
        "MAX_SEQ_LENGTH=128\n",
        "FAKE_INDEX = 0"
      ],
      "metadata": {
        "id": "uhc3sQapM94B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_emb():\n",
        "  return empty_sentence[0]\n",
        "\n",
        "def pad_emb(current_emb, seq_len):\n",
        "  if len(current_emb) > seq_len:\n",
        "    return current_emb[0:seq_len]\n",
        "  padding =  np.array([dummy_emb()] * (seq_len - len(current_emb)), dtype = 'double')\n",
        "  return np.concatenate([current_emb, padding], axis=0)\n",
        "\n",
        "def pad_label(current_label, seq_len):\n",
        "  if len(current_label) > seq_len:\n",
        "    return current_label[0:seq_len]\n",
        "  padding =  [FAKE_INDEX] * (seq_len - len(current_label))\n",
        "  # print(current_label, padding)\n",
        "  return np.concatenate([current_label, padding], axis=0)"
      ],
      "metadata": {
        "id": "6W4M_kc7VoLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class WikiPandasDfDataSet(Dataset):\n",
        "  def __init__(self, input_df):\n",
        "    self.pandas_df = input_df\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    seq = np.array(self.pandas_df.iloc[index][\"emb\"], dtype='double')\n",
        "    label = np.array(self.pandas_df.iloc[index][\"label\"], dtype='double')\n",
        "    return seq, label\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.pandas_df)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batched_seq = []\n",
        "    batched_label = []\n",
        "    for seqs, labels in batch:\n",
        "      try:\n",
        "        local_label = pad_label(labels, MAX_SEQ_LENGTH)\n",
        "        local_emb = pad_emb(seqs, MAX_SEQ_LENGTH)\n",
        "        batched_seq.append(local_emb)\n",
        "        batched_label.append(local_label)\n",
        "      except Exception as e:\n",
        "        print(\"collate_fn err:\", e)\n",
        "        continue\n",
        "    return torch.tensor(batched_seq).float(), torch.unsqueeze(torch.tensor(batched_label).float(), axis=2)"
      ],
      "metadata": {
        "id": "UTzzjQXaHWM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE_TRAIN = 32\n",
        "\n",
        "dataset_train = WikiPandasDfDataSet(read_df.head(6400))\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE_TRAIN, collate_fn = collate_fn, shuffle=True, drop_last=True)\n",
        "dataset_val = WikiPandasDfDataSet(read_df.tail(3200))\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=BATCH_SIZE_TRAIN, collate_fn = collate_fn, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "wVIBNogvNUz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Model code\n",
        "https://pytorch.org/tutorials/beginner/translation_transformer.html"
      ],
      "metadata": {
        "id": "cH6Y1q1ZM398"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import datetime\n",
        "import math\n",
        "from torch.nn import TransformerEncoderLayer"
      ],
      "metadata": {
        "id": "xWFmR6bnM5my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size, dropout=0.1, maxlen=MAX_SEQ_LENGTH):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "\n",
        "class TransformerClassifierModel(nn.Module):\n",
        "  def __init__(self, emb_dim=384, nhead = 16):\n",
        "    super(TransformerClassifierModel, self).__init__()\n",
        "    self.transformer_encoder = TransformerEncoderLayer(d_model=emb_dim,\n",
        "                                                        nhead=nhead)\n",
        "    self.positional_encoding = PositionalEncoding(emb_dim)\n",
        "    self.classifier_layer = nn.Linear(emb_dim, 1)\n",
        "    self.activation = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, seq_input):\n",
        "    enc_emb = self.positional_encoding(seq_input)\n",
        "    trans_enc = self.transformer_encoder(enc_emb)\n",
        "    linear_output = self.classifier_layer(trans_enc)\n",
        "    return self.activation(linear_output)"
      ],
      "metadata": {
        "id": "TzyrFuSNM7MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop code"
      ],
      "metadata": {
        "id": "rx16dypKBg-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import f1_score,accuracy_score"
      ],
      "metadata": {
        "id": "AC8vMe59CvYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, is_early=False, max_batches=500):\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    step = 0\n",
        "    # iterate over batches\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        sequences, labels = batch[0].to(device),batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        preds = model(sequences)\n",
        "        loss = CELoss(preds, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # progress update after every 100 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "            print(\"loss\",loss.item())\n",
        "            torch.cuda.empty_cache()\n",
        "            if is_early and step>=max_batches:\n",
        "                print(\"early stopping...\")\n",
        "                break\n",
        "        step+=1\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / step\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss\n",
        "\n",
        "def evaluate(dev_dataloader, is_early=False, max_batches=500):\n",
        "  \n",
        "    print(\"\\nEvaluating...\")\n",
        "  \n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    eval_preds = []\n",
        "    eval_labels = []\n",
        "    curr_examples = 0\n",
        "\n",
        "    # iterate over batches\n",
        "    step = 0\n",
        "    for batch in tqdm(dev_dataloader):\n",
        "    \n",
        "      # Progress update every 10 batches.\n",
        "      if step % 10 == 0 and not step == 0:\n",
        "    \n",
        "        # # Report progress.\n",
        "        # temp = np.delete(total_preds,0,0)\n",
        "        # print('  Batch {:>5,}  of  {:>5,} accuracy {}.'.format(step, len(dev_dataloader), accuracy_score(list(temp[:,0]),list(temp[:,1]))))\n",
        "        \n",
        "        # print(\"F1 score {}\".format(f1_score(list(temp[:,0]),list(temp[:,1]),average=\"macro\")))\n",
        "        if is_early and step>=max_batches:\n",
        "            print(\"early stopping...\")\n",
        "            break\n",
        "      # push the batch to gpu\n",
        "      #batch = [t.to(device) for t in batch]\n",
        "  \n",
        "\n",
        "      sequences, labels = batch[0].to(device),batch[1].to(device)\n",
        "      curr_examples += len(labels)\n",
        "      # deactivate autograd\n",
        "      with torch.no_grad():\n",
        "    \n",
        "      # model predictions\n",
        "          preds = model(sequences)\n",
        "\n",
        "          # compute the validation loss between actual and predicted values\n",
        "          loss = CELoss(preds,labels)\n",
        "\n",
        "          total_loss = total_loss + loss.item()\n",
        "          eval_preds += preds.detach().cpu().numpy().flatten().tolist()\n",
        "          eval_labels += labels.detach().cpu().numpy().flatten().tolist()\n",
        "      step+=1\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / step \n",
        "\n",
        "    return avg_loss, eval_preds, eval_labels"
      ],
      "metadata": {
        "id": "bnmLVpKPBjX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARING_RATE = 0.001\n",
        "NUM_EPOCS = 5\n",
        "\n",
        "model = TransformerClassifierModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "CELoss = nn.BCELoss()\n",
        "optimizer = AdamW(model.parameters(),lr = LEARING_RATE)\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "accuracy_list = []\n",
        "f1_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCS):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, NUM_EPOCS))\n",
        "    \n",
        "    #train model\n",
        "    train_loss = train(train_dataloader, is_early=True)\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, e_pred, e_label = evaluate(val_dataloader, is_early=True)\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    # accuracy_list.append(accuracy)\n",
        "    # f1_list.append(valid_f1)\n",
        "\n",
        "    print('Train loss:', train_loss, 'Val loss:', valid_loss)\n",
        "\n",
        "    for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
        "      labels_bool = [ elem > 0 for elem in e_label]\n",
        "      preds_bool = [elem > threshold for elem in e_pred]\n",
        "      accuracy = accuracy_score(labels_bool, preds_bool)\n",
        "      valid_f1 = f1_score(labels_bool, preds_bool,average=\"macro\")\n",
        "      print('Threshold:', threshold,'Accuracy:', accuracy, 'F1:', valid_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeS4kbtgGYRL",
        "outputId": "37daff05-a8f1-4a13-ee21-86bfee937564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 52/200 [00:06<00:19,  7.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of    200.\n",
            "loss 0.21984297037124634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▎     | 85/200 [00:10<00:13,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 101/200 [00:12<00:12,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "  Batch   100  of    200.\n",
            "loss 0.12895075976848602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 152/200 [00:19<00:05,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   150  of    200.\n",
            "loss 0.09535811096429825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 154/200 [00:19<00:05,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 182/200 [00:22<00:02,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 197/200 [00:24<00:00,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 93/100 [00:10<00:00,  9.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.13021964525803922 Val loss: 0.08993701655417681\n",
            "Threshold: 0.1 Accuracy: 0.9047138754298218 F1: 0.718971151217429\n",
            "Threshold: 0.2 Accuracy: 0.9047163175992498 F1: 0.7189750627554179\n",
            "Threshold: 0.3 Accuracy: 0.9047236441075336 F1: 0.7189867978598046\n",
            "Threshold: 0.4 Accuracy: 0.9517280790872148 F1: 0.5432156455821004\n",
            "Threshold: 0.5 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.6 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "\n",
            " Epoch 2 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 3/200 [00:00<00:23,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 52/200 [00:06<00:18,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of    200.\n",
            "loss 0.10896479338407516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 102/200 [00:12<00:12,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    200.\n",
            "loss 0.09142374992370605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 106/200 [00:13<00:11,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 152/200 [00:18<00:06,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   150  of    200.\n",
            "loss 0.057646263390779495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▎ | 165/200 [00:20<00:04,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [00:23<00:01,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 93/100 [00:10<00:00,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  9.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.09302549241110683 Val loss: 0.08942818362265825\n",
            "Threshold: 0.1 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.2 Accuracy: 0.9047138754298218 F1: 0.718971151217429\n",
            "Threshold: 0.3 Accuracy: 0.9528441505157862 F1: 0.5313993950424183\n",
            "Threshold: 0.4 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.5 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.6 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "\n",
            " Epoch 3 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 22/200 [00:02<00:21,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 24/200 [00:02<00:21,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 52/200 [00:06<00:18,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of    200.\n",
            "loss 0.09670725464820862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 102/200 [00:12<00:12,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    200.\n",
            "loss 0.14699867367744446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 119/200 [00:14<00:09,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 152/200 [00:18<00:06,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   150  of    200.\n",
            "loss 0.10054260492324829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 159/200 [00:19<00:05,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 173/200 [00:21<00:03,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 93/100 [00:10<00:00,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.09285081770271063 Val loss: 0.09055008932948112\n",
            "Threshold: 0.1 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.2 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.3 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.4 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.5 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.6 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "\n",
            " Epoch 4 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 52/200 [00:06<00:18,  7.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of    200.\n",
            "loss 0.09447755664587021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 54/200 [00:06<00:17,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▎      | 65/200 [00:08<00:16,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 90/200 [00:11<00:13,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 102/200 [00:12<00:12,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    200.\n",
            "loss 0.10238233953714371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 152/200 [00:18<00:06,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   150  of    200.\n",
            "loss 0.08499161899089813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 158/200 [00:19<00:05,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 176/200 [00:21<00:02,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 93/100 [00:10<00:00,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  9.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.09453334206715226 Val loss: 0.0892039430513978\n",
            "Threshold: 0.1 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.2 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.3 Accuracy: 0.9047163175992498 F1: 0.7189816450489994\n",
            "Threshold: 0.4 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.5 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.6 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "\n",
            " Epoch 5 / 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 8/200 [00:00<00:22,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 52/200 [00:06<00:18,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    50  of    200.\n",
            "loss 0.0710487961769104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 70/200 [00:08<00:16,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:12<00:12,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 102/200 [00:12<00:12,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    200.\n",
            "loss 0.07450773566961288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 122/200 [00:14<00:09,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 152/200 [00:18<00:06,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   150  of    200.\n",
            "loss 0.10210190713405609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 190/200 [00:23<00:01,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:24<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 93/100 [00:10<00:00,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collate_fn err: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  8.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.09256078088656068 Val loss: 0.08907548669725657\n",
            "Threshold: 0.1 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.2 Accuracy: 0.9047187597686777 F1: 0.7189921386248961\n",
            "Threshold: 0.3 Accuracy: 0.9066041145670523 F1: 0.7183743339157794\n",
            "Threshold: 0.4 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.5 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n",
            "Threshold: 0.6 Accuracy: 0.9541287316348859 F1: 0.4882629870738514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = transformer_encoder(src)"
      ],
      "metadata": {
        "id": "ORf4sMTlYpRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhVZXjvibFcx",
        "outputId": "0b3d865c-9d1b-4b31-9353-645184afc61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = encoder_layer(src)"
      ],
      "metadata": {
        "id": "D6hT3SkahiA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJPKTOdyiCRl",
        "outputId": "6e617b04-140e-4b93-be30-9c1c3370df18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
        "src = torch.rand((10, 32, 512))\n",
        "tgt = torch.rand((20, 32, 512))\n",
        "out = transformer_model(src, tgt)"
      ],
      "metadata": {
        "id": "KMxkgWXyiDUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVGba7aFEFyB",
        "outputId": "43705308-1d05-406d-843f-1c94c8d19243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sF1cJzUwEHfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y8yi4XS2-YSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}